{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4131df-7b9c-44ce-8f3e-22389cdb2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "using QuantumCollocation\n",
    "using NamedTrajectories\n",
    "using TrajectoryIndexingUtils\n",
    "using Flux\n",
    "using ReinforcementLearning\n",
    "using IntervalSets\n",
    "using LinearAlgebra\n",
    "using Base\n",
    "using Distributions\n",
    "using Statistics\n",
    "using Printf\n",
    "using Reexport\n",
    "using Revise\n",
    "\n",
    "includet(\"RL-Copy1.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e079ef4-c499-42e3-b033-650d04c6161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RZ_traj = load_traj(\"RZ_pretrained.jld2\")\n",
    "\n",
    "const Units = 1e9\n",
    "const MHz = 1e6 / Units\n",
    "const GHz = 1e9 / Units\n",
    "const ns = 1e-9 * Units\n",
    "const μs = 1e-6 * Units\n",
    ";\n",
    "\n",
    "\n",
    "# Operators\n",
    "const Paulis = Dict(\n",
    "    \"I\" => Matrix{ComplexF64}([1 0; 0 1]),\n",
    "    \"X\" => Matrix{ComplexF64}([0 1; 1 0]),\n",
    "    \"Y\" => Matrix{ComplexF64}([0 im; -im 0]),\n",
    "    \"Z\" => Matrix{ComplexF64}([1 0; 0 -1]),\n",
    ")\n",
    "\n",
    "rz_op(theta) = exp(-im/2 * theta[1] * Paulis[\"Z\"]);\n",
    "\n",
    "RZ = Gate(1,rz_op)\n",
    "\n",
    "H_drives = [\n",
    "     Paulis[\"X\"],Paulis[\"Y\"]\n",
    "]\n",
    "system = QuantumSystem(H_drives);\n",
    "t_f = 10* ns\n",
    "n_steps = 51\n",
    "times = range(0, t_f, n_steps)  # Alternative: collect(0:Δt:t_f)\n",
    "n_controls=1\n",
    "n_qubits=1;\n",
    "Δt = times[2] - times[1]\n",
    "\n",
    "N = 11\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8320b221-5186-4741-8f85-b56dcb42eda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GatePolicy(Chain(Dense(14 => 16, relu), Dense(16 => 16, relu), Dense(16 => 2, softsign)), Chain(Dense(14 => 16, relu), Dense(16 => 16, relu), Dense(16 => 1, softsign)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pretraining_Env = PretrainingGateEnv(\n",
    "                                    system = system,\n",
    "                                    Δt=Δt,\n",
    "                                    T=n_steps,\n",
    "                                    g=RZ,\n",
    "                                    N=11,\n",
    "                                    pretraining_trajectory=RZ_traj;\n",
    "                                    dda_bound=1.0\n",
    "                                    )\n",
    "\n",
    "Training_Env = TrainingGateEnv(\n",
    "                            system = system,\n",
    "                            Δt=Δt,\n",
    "                            T=n_steps,\n",
    "                            g=RZ;\n",
    "                            dda_bound=1.0\n",
    "                            );\n",
    "\n",
    "policy = GatePolicy(Training_Env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd932f6-aacf-46b6-bd4f-fdadd424ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards,acts,states = SampleTrajectory(policy,Pretraining_Env)\n",
    "a=Pretraining_Env.a\n",
    "da=Pretraining_Env.da\n",
    "dda=Pretraining_Env.dda\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8640e96d-85e3-49f5-9dcb-38a47c314db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9938696958458386"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(getTrajectoryLoss(Pretraining_Env)-sum(rewards))/getTrajectoryLoss(Pretraining_Env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e4d246-a1f4-4a0e-9467-c1e975056bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3236895057016784e-29"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((euler(dda,n_steps,Δt)-a).^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2801c67-9ff0-4a3c-aff6-8d87d800bb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Float64}:\n",
       "  0.0\n",
       "  8.326672684688674e-17\n",
       "  5.551115123125783e-17\n",
       " -5.551115123125783e-17\n",
       " -8.326672684688674e-17\n",
       "  0.0\n",
       " -5.551115123125783e-17\n",
       " -5.551115123125783e-17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unitary_rollout(operator_to_iso_vec([1+0.0im 0; 0 1]),a,Δt,system)[:,end]-Pretraining_Env.current_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d123fe-f8ab-492a-b7d7-849cc5bac12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards,acts,states = SampleTrajectory(policy,Training_Env)\n",
    "a=Training_Env.a\n",
    "da=Training_Env.da\n",
    "dda=Training_Env.dda\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1871a35b-7d35-45be-96eb-3f7adf20a19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9976525330130596"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(getTrajectoryLoss(Training_Env)-sum(rewards))/getTrajectoryLoss(Training_Env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "108f672d-9728-4133-bca5-506565678c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.565828725393675e-29"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((euler(dda,n_steps,Δt)-a).^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e4b5347-dd8c-4ea2-b202-91bd85c6e17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Float64}:\n",
       "  2.7755575615628914e-16\n",
       " -2.7755575615628914e-17\n",
       "  9.020562075079397e-17\n",
       "  2.220446049250313e-16\n",
       "  2.7755575615628914e-17\n",
       "  2.7755575615628914e-16\n",
       "  2.220446049250313e-16\n",
       " -9.020562075079397e-17"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unitary_rollout(operator_to_iso_vec([1+0.0im 0; 0 1]),a,Δt,system)[:,end]-Training_Env.current_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc2ad953-861f-4018-b7a8-3e0acb5d0607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations 1 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.70695\n",
      "Final KL: 0.46478\n",
      "Mean Policy Loss: 0.05685\n",
      "Mean Value Loss: 1.13877\n",
      "-------------------------\n",
      "Iterations 2 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.71837\n",
      "Final KL: 0.90752\n",
      "Mean Policy Loss: 0.82135\n",
      "Mean Value Loss: 0.89322\n",
      "-------------------------\n",
      "Iterations 3 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.78999\n",
      "Final KL: 0.09607\n",
      "Mean Policy Loss: 0.03705\n",
      "Mean Value Loss: 0.71744\n",
      "-------------------------\n",
      "Iterations 4 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.69126\n",
      "Final KL: 1.81478\n",
      "Mean Policy Loss: 0.00140\n",
      "Mean Value Loss: 0.64161\n",
      "-------------------------\n",
      "Iterations 5 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.75841\n",
      "Final KL: 0.43342\n",
      "Mean Policy Loss: 0.02600\n",
      "Mean Value Loss: 0.41784\n",
      "-------------------------\n",
      "Iterations 6 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.65029\n",
      "Final KL: 0.08781\n",
      "Mean Policy Loss: 0.00201\n",
      "Mean Value Loss: 0.19362\n",
      "-------------------------\n",
      "Iterations 7 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.84332\n",
      "Final KL: 0.12462\n",
      "Mean Policy Loss: -0.00229\n",
      "Mean Value Loss: 0.62900\n",
      "-------------------------\n",
      "Iterations 8 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.81389\n",
      "Final KL: 0.07714\n",
      "Mean Policy Loss: 0.02982\n",
      "Mean Value Loss: 0.60056\n",
      "-------------------------\n",
      "Iterations 9 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.63038\n",
      "Final KL: 0.18930\n",
      "Mean Policy Loss: 0.02990\n",
      "Mean Value Loss: 0.36773\n",
      "-------------------------\n",
      "Iterations 10 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.80005\n",
      "Final KL: 0.29010\n",
      "Mean Policy Loss: 0.01505\n",
      "Mean Value Loss: 0.38901\n",
      "-------------------------\n",
      "Iterations 11 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.98110\n",
      "Final KL: 0.07014\n",
      "Mean Policy Loss: 0.03014\n",
      "Mean Value Loss: 0.47632\n",
      "-------------------------\n",
      "Iterations 12 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.73099\n",
      "Final KL: 54.22445\n",
      "Mean Policy Loss: 0.02852\n",
      "Mean Value Loss: 0.36316\n",
      "-------------------------\n",
      "Iterations 13 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.42739\n",
      "Final KL: 0.16303\n",
      "Mean Policy Loss: 0.02146\n",
      "Mean Value Loss: 0.13611\n",
      "-------------------------\n",
      "Iterations 14 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.71391\n",
      "Final KL: 0.09487\n",
      "Mean Policy Loss: 0.03772\n",
      "Mean Value Loss: 0.43511\n",
      "-------------------------\n",
      "Iterations 15 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.98984\n",
      "Final KL: 9.95742\n",
      "Mean Policy Loss: 0.01395\n",
      "Mean Value Loss: 0.73384\n",
      "-------------------------\n",
      "Iterations 16 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.92552\n",
      "Final KL: 0.11768\n",
      "Mean Policy Loss: -0.00136\n",
      "Mean Value Loss: 0.52431\n",
      "-------------------------\n",
      "Iterations 17 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.60935\n",
      "Final KL: 0.22320\n",
      "Mean Policy Loss: 0.01393\n",
      "Mean Value Loss: 0.25742\n",
      "-------------------------\n",
      "Iterations 18 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.59017\n",
      "Final KL: 0.13147\n",
      "Mean Policy Loss: 0.03377\n",
      "Mean Value Loss: 0.29483\n",
      "-------------------------\n",
      "Iterations 19 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.64927\n",
      "Final KL: 0.16574\n",
      "Mean Policy Loss: 0.00856\n",
      "Mean Value Loss: 0.51781\n",
      "-------------------------\n",
      "Iterations 20 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.69338\n",
      "Final KL: 2483587.25000\n",
      "Mean Policy Loss: 0.00961\n",
      "Mean Value Loss: 0.28578\n",
      "-------------------------\n",
      "Iterations 21 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.72559\n",
      "Final KL: 0.24183\n",
      "Mean Policy Loss: 0.00550\n",
      "Mean Value Loss: 0.23797\n",
      "-------------------------\n",
      "Iterations 22 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.96393\n",
      "Final KL: 0.06038\n",
      "Mean Policy Loss: 0.02470\n",
      "Mean Value Loss: 0.63261\n",
      "-------------------------\n",
      "Iterations 23 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.64778\n",
      "Final KL: 0.82876\n",
      "Mean Policy Loss: -0.00629\n",
      "Mean Value Loss: 0.23143\n",
      "-------------------------\n",
      "Iterations 24 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.75535\n",
      "Final KL: 0.36108\n",
      "Mean Policy Loss: 0.05829\n",
      "Mean Value Loss: 0.46292\n",
      "-------------------------\n",
      "Iterations 25 Complete\n",
      "Epochs 10 \n",
      "Mean Rtg: -1.11590\n",
      "Final KL: 0.04364\n",
      "Mean Policy Loss: -0.01606\n",
      "Mean Value Loss: 0.54228\n",
      "-------------------------\n",
      "Iterations 26 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.77897\n",
      "Final KL: 17.16076\n",
      "Mean Policy Loss: -0.01619\n",
      "Mean Value Loss: 0.22473\n",
      "-------------------------\n",
      "Iterations 27 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.70796\n",
      "Final KL: 0.24308\n",
      "Mean Policy Loss: 0.01234\n",
      "Mean Value Loss: 0.28537\n",
      "-------------------------\n",
      "Iterations 28 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.87314\n",
      "Final KL: 0.16395\n",
      "Mean Policy Loss: 0.03342\n",
      "Mean Value Loss: 0.46862\n",
      "-------------------------\n",
      "Iterations 29 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.98601\n",
      "Final KL: 0.10366\n",
      "Mean Policy Loss: 0.01154\n",
      "Mean Value Loss: 0.92000\n",
      "-------------------------\n",
      "Iterations 30 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.73667\n",
      "Final KL: 0.13364\n",
      "Mean Policy Loss: 0.00711\n",
      "Mean Value Loss: 0.39123\n",
      "-------------------------\n",
      "Iterations 31 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.87929\n",
      "Final KL: 0.05946\n",
      "Mean Policy Loss: 0.02648\n",
      "Mean Value Loss: 0.57238\n",
      "-------------------------\n",
      "Iterations 32 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.82284\n",
      "Final KL: 0.36630\n",
      "Mean Policy Loss: 0.02827\n",
      "Mean Value Loss: 0.28802\n",
      "-------------------------\n",
      "Iterations 33 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.88991\n",
      "Final KL: 0.08720\n",
      "Mean Policy Loss: 0.02965\n",
      "Mean Value Loss: 0.47700\n",
      "-------------------------\n",
      "Iterations 34 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.80813\n",
      "Final KL: 12.89233\n",
      "Mean Policy Loss: 0.02123\n",
      "Mean Value Loss: 0.37476\n",
      "-------------------------\n",
      "Iterations 35 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.59265\n",
      "Final KL: 8754.26758\n",
      "Mean Policy Loss: 0.02372\n",
      "Mean Value Loss: 0.25748\n",
      "-------------------------\n",
      "Iterations 36 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.68563\n",
      "Final KL: 0.08579\n",
      "Mean Policy Loss: 0.02645\n",
      "Mean Value Loss: 0.26012\n",
      "-------------------------\n",
      "Iterations 37 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.84098\n",
      "Final KL: 0.10405\n",
      "Mean Policy Loss: 0.01282\n",
      "Mean Value Loss: 0.33200\n",
      "-------------------------\n",
      "Iterations 38 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.92818\n",
      "Final KL: 0.08294\n",
      "Mean Policy Loss: 0.00258\n",
      "Mean Value Loss: 0.31365\n",
      "-------------------------\n",
      "Iterations 39 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.96181\n",
      "Final KL: 0.33140\n",
      "Mean Policy Loss: 0.15675\n",
      "Mean Value Loss: 0.49876\n",
      "-------------------------\n",
      "Iterations 40 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.62758\n",
      "Final KL: 2.36434\n",
      "Mean Policy Loss: 0.00291\n",
      "Mean Value Loss: 0.14325\n",
      "-------------------------\n",
      "Iterations 41 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.52969\n",
      "Final KL: 0.15149\n",
      "Mean Policy Loss: -0.00420\n",
      "Mean Value Loss: 0.11938\n",
      "-------------------------\n",
      "Iterations 42 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.67308\n",
      "Final KL: 0.05577\n",
      "Mean Policy Loss: 0.00108\n",
      "Mean Value Loss: 0.26095\n",
      "-------------------------\n",
      "Iterations 43 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -1.11852\n",
      "Final KL: 0.19256\n",
      "Mean Policy Loss: 0.01513\n",
      "Mean Value Loss: 0.51962\n",
      "-------------------------\n",
      "Iterations 44 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.80090\n",
      "Final KL: 2.71242\n",
      "Mean Policy Loss: 0.01782\n",
      "Mean Value Loss: 0.22282\n",
      "-------------------------\n",
      "Iterations 45 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.79633\n",
      "Final KL: 0.05086\n",
      "Mean Policy Loss: 0.02845\n",
      "Mean Value Loss: 0.33125\n",
      "-------------------------\n",
      "Iterations 46 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.75349\n",
      "Final KL: 0.11537\n",
      "Mean Policy Loss: 0.01343\n",
      "Mean Value Loss: 0.41809\n",
      "-------------------------\n",
      "Iterations 47 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.50450\n",
      "Final KL: 0.14350\n",
      "Mean Policy Loss: 0.03731\n",
      "Mean Value Loss: 0.29124\n",
      "-------------------------\n",
      "Iterations 48 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.72134\n",
      "Final KL: 0.54724\n",
      "Mean Policy Loss: 0.00405\n",
      "Mean Value Loss: 0.33896\n",
      "-------------------------\n",
      "Iterations 49 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.76384\n",
      "Final KL: 0.05322\n",
      "Mean Policy Loss: 0.01257\n",
      "Mean Value Loss: 0.45873\n",
      "-------------------------\n",
      "Iterations 50 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.67011\n",
      "Final KL: 0.19647\n",
      "Mean Policy Loss: 0.00699\n",
      "Mean Value Loss: 0.16219\n",
      "-------------------------\n",
      "Iterations 51 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.73211\n",
      "Final KL: 0.35736\n",
      "Mean Policy Loss: 0.04785\n",
      "Mean Value Loss: 0.33916\n",
      "-------------------------\n",
      "Iterations 52 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -1.02548\n",
      "Final KL: 0.14481\n",
      "Mean Policy Loss: 0.00807\n",
      "Mean Value Loss: 0.48277\n",
      "-------------------------\n",
      "Iterations 53 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -1.05021\n",
      "Final KL: 0.34449\n",
      "Mean Policy Loss: 0.02461\n",
      "Mean Value Loss: 1.18260\n",
      "-------------------------\n",
      "Iterations 54 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.52289\n",
      "Final KL: 0.62461\n",
      "Mean Policy Loss: 0.00733\n",
      "Mean Value Loss: 0.17920\n",
      "-------------------------\n",
      "Iterations 55 Complete\n",
      "Epochs 3 \n",
      "Mean Rtg: -0.82286\n",
      "Final KL: 0.18110\n",
      "Mean Policy Loss: 0.01094\n",
      "Mean Value Loss: 0.35123\n",
      "-------------------------\n",
      "Iterations 56 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.97866\n",
      "Final KL: 0.08094\n",
      "Mean Policy Loss: 0.08154\n",
      "Mean Value Loss: 0.33837\n",
      "-------------------------\n",
      "Iterations 57 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.86155\n",
      "Final KL: 0.11001\n",
      "Mean Policy Loss: 0.03584\n",
      "Mean Value Loss: 0.74392\n",
      "-------------------------\n",
      "Iterations 58 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.72081\n",
      "Final KL: 0.30577\n",
      "Mean Policy Loss: 0.37903\n",
      "Mean Value Loss: 0.40734\n",
      "-------------------------\n",
      "Iterations 59 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.51884\n",
      "Final KL: 0.06539\n",
      "Mean Policy Loss: 0.06749\n",
      "Mean Value Loss: 0.09751\n",
      "-------------------------\n",
      "Iterations 60 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.68077\n",
      "Final KL: 0.24066\n",
      "Mean Policy Loss: 0.08922\n",
      "Mean Value Loss: 0.32358\n",
      "-------------------------\n",
      "Iterations 61 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.60089\n",
      "Final KL: 50.26731\n",
      "Mean Policy Loss: 0.01733\n",
      "Mean Value Loss: 0.19012\n",
      "-------------------------\n",
      "Iterations 62 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.41501\n",
      "Final KL: 0.15561\n",
      "Mean Policy Loss: 0.06529\n",
      "Mean Value Loss: 0.06717\n",
      "-------------------------\n",
      "Iterations 63 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.85689\n",
      "Final KL: 0.07047\n",
      "Mean Policy Loss: 0.01811\n",
      "Mean Value Loss: 0.54675\n",
      "-------------------------\n",
      "Iterations 64 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.58180\n",
      "Final KL: 0.13470\n",
      "Mean Policy Loss: 0.06554\n",
      "Mean Value Loss: 0.16285\n",
      "-------------------------\n",
      "Iterations 65 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.71932\n",
      "Final KL: 0.08839\n",
      "Mean Policy Loss: 0.15278\n",
      "Mean Value Loss: 0.32485\n",
      "-------------------------\n",
      "Iterations 66 Complete\n",
      "Epochs 10 \n",
      "Mean Rtg: -0.99164\n",
      "Final KL: 0.02825\n",
      "Mean Policy Loss: -0.01354\n",
      "Mean Value Loss: 0.54322\n",
      "-------------------------\n",
      "Iterations 67 Complete\n",
      "Epochs 3 \n",
      "Mean Rtg: -0.98994\n",
      "Final KL: 0.17070\n",
      "Mean Policy Loss: 0.05721\n",
      "Mean Value Loss: 0.69246\n",
      "-------------------------\n",
      "Iterations 68 Complete\n",
      "Epochs 3 \n",
      "Mean Rtg: -0.77381\n",
      "Final KL: 0.38014\n",
      "Mean Policy Loss: 0.00300\n",
      "Mean Value Loss: 0.24390\n",
      "-------------------------\n",
      "Iterations 69 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.80390\n",
      "Final KL: 0.36337\n",
      "Mean Policy Loss: 0.02018\n",
      "Mean Value Loss: 0.41173\n",
      "-------------------------\n",
      "Iterations 70 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.72217\n",
      "Final KL: 0.15468\n",
      "Mean Policy Loss: 0.03011\n",
      "Mean Value Loss: 0.35967\n",
      "-------------------------\n",
      "Iterations 71 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.72254\n",
      "Final KL: 0.08617\n",
      "Mean Policy Loss: 0.01499\n",
      "Mean Value Loss: 0.25001\n",
      "-------------------------\n",
      "Iterations 72 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.72593\n",
      "Final KL: 0.41475\n",
      "Mean Policy Loss: 0.00223\n",
      "Mean Value Loss: 0.37449\n",
      "-------------------------\n",
      "Iterations 73 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.49838\n",
      "Final KL: 0.06217\n",
      "Mean Policy Loss: 0.03191\n",
      "Mean Value Loss: 0.35292\n",
      "-------------------------\n",
      "Iterations 74 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.72367\n",
      "Final KL: 0.13772\n",
      "Mean Policy Loss: 0.08525\n",
      "Mean Value Loss: 0.30854\n",
      "-------------------------\n",
      "Iterations 75 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.99674\n",
      "Final KL: 0.15017\n",
      "Mean Policy Loss: 0.02318\n",
      "Mean Value Loss: 0.51760\n",
      "-------------------------\n",
      "Iterations 76 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.61834\n",
      "Final KL: 0.07193\n",
      "Mean Policy Loss: -0.00018\n",
      "Mean Value Loss: 0.36208\n",
      "-------------------------\n",
      "Iterations 77 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.98651\n",
      "Final KL: 0.05077\n",
      "Mean Policy Loss: -0.00547\n",
      "Mean Value Loss: 0.35983\n",
      "-------------------------\n",
      "Iterations 78 Complete\n",
      "Epochs 3 \n",
      "Mean Rtg: -0.83021\n",
      "Final KL: 0.05361\n",
      "Mean Policy Loss: -0.00288\n",
      "Mean Value Loss: 0.31104\n",
      "-------------------------\n",
      "Iterations 79 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.98726\n",
      "Final KL: 0.05159\n",
      "Mean Policy Loss: 0.36666\n",
      "Mean Value Loss: 0.92985\n",
      "-------------------------\n",
      "Iterations 80 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.79650\n",
      "Final KL: 0.07755\n",
      "Mean Policy Loss: 0.03668\n",
      "Mean Value Loss: 0.18093\n",
      "-------------------------\n",
      "Iterations 81 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.80627\n",
      "Final KL: 0.50547\n",
      "Mean Policy Loss: 0.00758\n",
      "Mean Value Loss: 0.38771\n",
      "-------------------------\n",
      "Iterations 82 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.77034\n",
      "Final KL: 0.05092\n",
      "Mean Policy Loss: 0.01766\n",
      "Mean Value Loss: 0.27485\n",
      "-------------------------\n",
      "Iterations 83 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.69727\n",
      "Final KL: 0.08296\n",
      "Mean Policy Loss: 0.08953\n",
      "Mean Value Loss: 0.21036\n",
      "-------------------------\n",
      "Iterations 84 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.97482\n",
      "Final KL: 0.61584\n",
      "Mean Policy Loss: 0.00780\n",
      "Mean Value Loss: 0.50771\n",
      "-------------------------\n",
      "Iterations 85 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.81606\n",
      "Final KL: 0.22483\n",
      "Mean Policy Loss: 0.00866\n",
      "Mean Value Loss: 0.33606\n",
      "-------------------------\n",
      "Iterations 86 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.89496\n",
      "Final KL: 0.08447\n",
      "Mean Policy Loss: 0.03274\n",
      "Mean Value Loss: 0.46709\n",
      "-------------------------\n",
      "Iterations 87 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.80254\n",
      "Final KL: 0.08937\n",
      "Mean Policy Loss: 0.01142\n",
      "Mean Value Loss: 0.52315\n",
      "-------------------------\n",
      "Iterations 88 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -1.04401\n",
      "Final KL: 0.22892\n",
      "Mean Policy Loss: 0.01488\n",
      "Mean Value Loss: 0.44332\n",
      "-------------------------\n",
      "Iterations 89 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.58856\n",
      "Final KL: 0.21558\n",
      "Mean Policy Loss: 0.01761\n",
      "Mean Value Loss: 0.31867\n",
      "-------------------------\n",
      "Iterations 90 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.90041\n",
      "Final KL: 0.71594\n",
      "Mean Policy Loss: 0.00249\n",
      "Mean Value Loss: 1.22015\n",
      "-------------------------\n",
      "Iterations 91 Complete\n",
      "Epochs 10 \n",
      "Mean Rtg: -0.65350\n",
      "Final KL: 0.03457\n",
      "Mean Policy Loss: -0.02091\n",
      "Mean Value Loss: 0.16512\n",
      "-------------------------\n",
      "Iterations 92 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.83543\n",
      "Final KL: 0.06246\n",
      "Mean Policy Loss: -0.00857\n",
      "Mean Value Loss: 0.32906\n",
      "-------------------------\n",
      "Iterations 93 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.72522\n",
      "Final KL: 0.07382\n",
      "Mean Policy Loss: 0.00122\n",
      "Mean Value Loss: 0.24537\n",
      "-------------------------\n",
      "Iterations 94 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.85780\n",
      "Final KL: 0.08922\n",
      "Mean Policy Loss: 0.00132\n",
      "Mean Value Loss: 0.32974\n",
      "-------------------------\n",
      "Iterations 95 Complete\n",
      "Epochs 10 \n",
      "Mean Rtg: -0.84995\n",
      "Final KL: 0.02842\n",
      "Mean Policy Loss: -0.01836\n",
      "Mean Value Loss: 0.18891\n",
      "-------------------------\n",
      "Iterations 96 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.79029\n",
      "Final KL: 0.37614\n",
      "Mean Policy Loss: 0.01039\n",
      "Mean Value Loss: 0.82949\n",
      "-------------------------\n",
      "Iterations 97 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.83192\n",
      "Final KL: 0.26260\n",
      "Mean Policy Loss: 0.02974\n",
      "Mean Value Loss: 0.38192\n",
      "-------------------------\n",
      "Iterations 98 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.95442\n",
      "Final KL: 0.13380\n",
      "Mean Policy Loss: 0.01626\n",
      "Mean Value Loss: 0.37867\n",
      "-------------------------\n",
      "Iterations 99 Complete\n",
      "Epochs 4 \n",
      "Mean Rtg: -0.69650\n",
      "Final KL: 0.05002\n",
      "Mean Policy Loss: -0.00637\n",
      "Mean Value Loss: 0.18628\n",
      "-------------------------\n",
      "Iterations 100 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.69472\n",
      "Final KL: 0.13747\n",
      "Mean Policy Loss: 0.00779\n",
      "Mean Value Loss: 0.19276\n",
      "-------------------------\n",
      "Iterations 101 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.95634\n",
      "Final KL: 0.11192\n",
      "Mean Policy Loss: 0.00247\n",
      "Mean Value Loss: 0.42402\n",
      "-------------------------\n",
      "Iterations 102 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.87993\n",
      "Final KL: 0.17385\n",
      "Mean Policy Loss: 0.05948\n",
      "Mean Value Loss: 0.25852\n",
      "-------------------------\n",
      "Iterations 103 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.74329\n",
      "Final KL: 0.06534\n",
      "Mean Policy Loss: 0.00300\n",
      "Mean Value Loss: 0.23447\n",
      "-------------------------\n",
      "Iterations 104 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.91802\n",
      "Final KL: 0.05957\n",
      "Mean Policy Loss: 0.02144\n",
      "Mean Value Loss: 0.54335\n",
      "-------------------------\n",
      "Iterations 105 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.95427\n",
      "Final KL: 1.52217\n",
      "Mean Policy Loss: 0.00817\n",
      "Mean Value Loss: 0.56705\n",
      "-------------------------\n",
      "Iterations 106 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.86659\n",
      "Final KL: 0.17522\n",
      "Mean Policy Loss: 0.04690\n",
      "Mean Value Loss: 0.45084\n",
      "-------------------------\n",
      "Iterations 107 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.77104\n",
      "Final KL: 0.29818\n",
      "Mean Policy Loss: 0.00635\n",
      "Mean Value Loss: 0.24641\n",
      "-------------------------\n",
      "Iterations 108 Complete\n",
      "Epochs 10 \n",
      "Mean Rtg: -0.59581\n",
      "Final KL: 0.02857\n",
      "Mean Policy Loss: -0.01564\n",
      "Mean Value Loss: 0.15300\n",
      "-------------------------\n",
      "Iterations 109 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.57844\n",
      "Final KL: 0.05803\n",
      "Mean Policy Loss: 0.00402\n",
      "Mean Value Loss: 0.14951\n",
      "-------------------------\n",
      "Iterations 110 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.82090\n",
      "Final KL: 0.05918\n",
      "Mean Policy Loss: 0.01673\n",
      "Mean Value Loss: 0.43510\n",
      "-------------------------\n",
      "Iterations 111 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.93723\n",
      "Final KL: 0.10718\n",
      "Mean Policy Loss: 0.01765\n",
      "Mean Value Loss: 0.30428\n",
      "-------------------------\n",
      "Iterations 112 Complete\n",
      "Epochs 9 \n",
      "Mean Rtg: -0.86518\n",
      "Final KL: 0.05695\n",
      "Mean Policy Loss: -0.00635\n",
      "Mean Value Loss: 0.26022\n",
      "-------------------------\n",
      "Iterations 113 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.55780\n",
      "Final KL: 0.09573\n",
      "Mean Policy Loss: 0.01416\n",
      "Mean Value Loss: 0.23325\n",
      "-------------------------\n",
      "Iterations 114 Complete\n",
      "Epochs 10 \n",
      "Mean Rtg: -0.80834\n",
      "Final KL: 0.02951\n",
      "Mean Policy Loss: -0.01592\n",
      "Mean Value Loss: 0.26967\n",
      "-------------------------\n",
      "Iterations 115 Complete\n",
      "Epochs 6 \n",
      "Mean Rtg: -0.92566\n",
      "Final KL: 0.07687\n",
      "Mean Policy Loss: -0.01260\n",
      "Mean Value Loss: 0.45110\n",
      "-------------------------\n",
      "Iterations 116 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.60886\n",
      "Final KL: 0.05533\n",
      "Mean Policy Loss: 0.00039\n",
      "Mean Value Loss: 0.13718\n",
      "-------------------------\n",
      "Iterations 117 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.94032\n",
      "Final KL: 4.40199\n",
      "Mean Policy Loss: 0.00007\n",
      "Mean Value Loss: 0.36331\n",
      "-------------------------\n",
      "Iterations 118 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.77225\n",
      "Final KL: 0.13652\n",
      "Mean Policy Loss: 0.02933\n",
      "Mean Value Loss: 0.30018\n",
      "-------------------------\n",
      "Iterations 119 Complete\n",
      "Epochs 10 \n",
      "Mean Rtg: -0.51405\n",
      "Final KL: 0.02607\n",
      "Mean Policy Loss: -0.01657\n",
      "Mean Value Loss: 0.20110\n",
      "-------------------------\n",
      "Iterations 120 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.76277\n",
      "Final KL: 0.47678\n",
      "Mean Policy Loss: -0.00342\n",
      "Mean Value Loss: 0.24145\n",
      "-------------------------\n",
      "Iterations 121 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.70898\n",
      "Final KL: 1.45476\n",
      "Mean Policy Loss: 0.00899\n",
      "Mean Value Loss: 0.40219\n",
      "-------------------------\n",
      "Iterations 122 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.60384\n",
      "Final KL: 0.06676\n",
      "Mean Policy Loss: -0.00708\n",
      "Mean Value Loss: 0.11684\n",
      "-------------------------\n",
      "Iterations 123 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.57866\n",
      "Final KL: 0.06072\n",
      "Mean Policy Loss: 0.02481\n",
      "Mean Value Loss: 0.28574\n",
      "-------------------------\n",
      "Iterations 124 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.52324\n",
      "Final KL: 0.73016\n",
      "Mean Policy Loss: 0.01519\n",
      "Mean Value Loss: 0.13392\n",
      "-------------------------\n",
      "Iterations 125 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.69192\n",
      "Final KL: 0.13885\n",
      "Mean Policy Loss: 0.01242\n",
      "Mean Value Loss: 0.19311\n",
      "-------------------------\n",
      "Iterations 126 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -1.07658\n",
      "Final KL: 0.25054\n",
      "Mean Policy Loss: 0.01362\n",
      "Mean Value Loss: 0.79895\n",
      "-------------------------\n",
      "Iterations 127 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.64731\n",
      "Final KL: 0.11870\n",
      "Mean Policy Loss: 0.02020\n",
      "Mean Value Loss: 0.28242\n",
      "-------------------------\n",
      "Iterations 128 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.55977\n",
      "Final KL: 0.08691\n",
      "Mean Policy Loss: 0.01683\n",
      "Mean Value Loss: 0.15753\n",
      "-------------------------\n",
      "Iterations 129 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.75931\n",
      "Final KL: 0.14611\n",
      "Mean Policy Loss: 0.03360\n",
      "Mean Value Loss: 0.27202\n",
      "-------------------------\n",
      "Iterations 130 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.63617\n",
      "Final KL: 0.12704\n",
      "Mean Policy Loss: 0.01467\n",
      "Mean Value Loss: 0.23549\n",
      "-------------------------\n",
      "Iterations 131 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.84330\n",
      "Final KL: 0.20926\n",
      "Mean Policy Loss: 0.01322\n",
      "Mean Value Loss: 0.37358\n",
      "-------------------------\n",
      "Iterations 132 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.51108\n",
      "Final KL: 0.38351\n",
      "Mean Policy Loss: 0.00278\n",
      "Mean Value Loss: 0.21693\n",
      "-------------------------\n",
      "Iterations 133 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.73099\n",
      "Final KL: 0.08344\n",
      "Mean Policy Loss: 0.01986\n",
      "Mean Value Loss: 0.18172\n",
      "-------------------------\n",
      "Iterations 134 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.91225\n",
      "Final KL: 3.59753\n",
      "Mean Policy Loss: 0.00974\n",
      "Mean Value Loss: 0.66819\n",
      "-------------------------\n",
      "Iterations 135 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.73987\n",
      "Final KL: 0.19875\n",
      "Mean Policy Loss: 0.00139\n",
      "Mean Value Loss: 0.16174\n",
      "-------------------------\n",
      "Iterations 136 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.87282\n",
      "Final KL: 0.13151\n",
      "Mean Policy Loss: 0.01181\n",
      "Mean Value Loss: 0.19737\n",
      "-------------------------\n",
      "Iterations 137 Complete\n",
      "Epochs 6 \n",
      "Mean Rtg: -0.71168\n",
      "Final KL: 0.07268\n",
      "Mean Policy Loss: -0.00514\n",
      "Mean Value Loss: 0.25195\n",
      "-------------------------\n",
      "Iterations 138 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.77097\n",
      "Final KL: 0.09772\n",
      "Mean Policy Loss: 0.02460\n",
      "Mean Value Loss: 0.22535\n",
      "-------------------------\n",
      "Iterations 139 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.59566\n",
      "Final KL: 0.07275\n",
      "Mean Policy Loss: 0.05146\n",
      "Mean Value Loss: 0.21444\n",
      "-------------------------\n",
      "Iterations 140 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.63222\n",
      "Final KL: 0.06522\n",
      "Mean Policy Loss: 0.03129\n",
      "Mean Value Loss: 0.13275\n",
      "-------------------------\n",
      "Iterations 141 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.89319\n",
      "Final KL: 0.08299\n",
      "Mean Policy Loss: 0.05042\n",
      "Mean Value Loss: 0.44357\n",
      "-------------------------\n",
      "Iterations 142 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.75161\n",
      "Final KL: 0.48744\n",
      "Mean Policy Loss: 0.00011\n",
      "Mean Value Loss: 0.26996\n",
      "-------------------------\n",
      "Iterations 143 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.82254\n",
      "Final KL: 0.41797\n",
      "Mean Policy Loss: 0.02879\n",
      "Mean Value Loss: 0.30655\n",
      "-------------------------\n",
      "Iterations 144 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.72157\n",
      "Final KL: 0.16443\n",
      "Mean Policy Loss: 0.01426\n",
      "Mean Value Loss: 0.08965\n",
      "-------------------------\n",
      "Iterations 145 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.64373\n",
      "Final KL: 0.07725\n",
      "Mean Policy Loss: 0.03132\n",
      "Mean Value Loss: 0.15009\n",
      "-------------------------\n",
      "Iterations 146 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.77148\n",
      "Final KL: 0.16641\n",
      "Mean Policy Loss: 0.00803\n",
      "Mean Value Loss: 0.28542\n",
      "-------------------------\n",
      "Iterations 147 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.75726\n",
      "Final KL: 0.06602\n",
      "Mean Policy Loss: 0.01742\n",
      "Mean Value Loss: 0.17869\n",
      "-------------------------\n",
      "Iterations 148 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -1.01372\n",
      "Final KL: 0.13513\n",
      "Mean Policy Loss: 0.05404\n",
      "Mean Value Loss: 0.47444\n",
      "-------------------------\n",
      "Iterations 149 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.69153\n",
      "Final KL: 0.24125\n",
      "Mean Policy Loss: 0.04648\n",
      "Mean Value Loss: 0.18572\n",
      "-------------------------\n",
      "Iterations 150 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -1.04922\n",
      "Final KL: 0.07948\n",
      "Mean Policy Loss: 0.02359\n",
      "Mean Value Loss: 0.40613\n",
      "-------------------------\n",
      "Iterations 151 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.78717\n",
      "Final KL: 0.05621\n",
      "Mean Policy Loss: 0.05159\n",
      "Mean Value Loss: 0.17899\n",
      "-------------------------\n",
      "Iterations 152 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.42923\n",
      "Final KL: 0.32620\n",
      "Mean Policy Loss: -0.00780\n",
      "Mean Value Loss: 0.10628\n",
      "-------------------------\n",
      "Iterations 153 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.48063\n",
      "Final KL: 0.28587\n",
      "Mean Policy Loss: 0.01502\n",
      "Mean Value Loss: 0.11853\n",
      "-------------------------\n",
      "Iterations 154 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.82031\n",
      "Final KL: 0.56363\n",
      "Mean Policy Loss: 0.05935\n",
      "Mean Value Loss: 0.33588\n",
      "-------------------------\n",
      "Iterations 155 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.81698\n",
      "Final KL: 0.53601\n",
      "Mean Policy Loss: 0.00575\n",
      "Mean Value Loss: 0.46764\n",
      "-------------------------\n",
      "Iterations 156 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.68298\n",
      "Final KL: 0.11403\n",
      "Mean Policy Loss: 0.02291\n",
      "Mean Value Loss: 0.20301\n",
      "-------------------------\n",
      "Iterations 157 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.82365\n",
      "Final KL: 0.40070\n",
      "Mean Policy Loss: 0.01273\n",
      "Mean Value Loss: 0.20381\n",
      "-------------------------\n",
      "Iterations 158 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.74508\n",
      "Final KL: 0.27692\n",
      "Mean Policy Loss: 0.01447\n",
      "Mean Value Loss: 0.23741\n",
      "-------------------------\n",
      "Iterations 159 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.70753\n",
      "Final KL: 0.10820\n",
      "Mean Policy Loss: 0.02583\n",
      "Mean Value Loss: 0.37653\n",
      "-------------------------\n",
      "Iterations 160 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.55959\n",
      "Final KL: 0.24012\n",
      "Mean Policy Loss: 0.01218\n",
      "Mean Value Loss: 0.21537\n",
      "-------------------------\n",
      "Iterations 161 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.75500\n",
      "Final KL: 0.25741\n",
      "Mean Policy Loss: 0.02033\n",
      "Mean Value Loss: 0.25248\n",
      "-------------------------\n",
      "Iterations 162 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.72442\n",
      "Final KL: 0.18406\n",
      "Mean Policy Loss: 0.01281\n",
      "Mean Value Loss: 0.25228\n",
      "-------------------------\n",
      "Iterations 163 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.81024\n",
      "Final KL: 10.53954\n",
      "Mean Policy Loss: 0.00969\n",
      "Mean Value Loss: 0.22403\n",
      "-------------------------\n",
      "Iterations 164 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.84002\n",
      "Final KL: 5.09911\n",
      "Mean Policy Loss: 0.03479\n",
      "Mean Value Loss: 0.26567\n",
      "-------------------------\n",
      "Iterations 165 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.68871\n",
      "Final KL: 0.06014\n",
      "Mean Policy Loss: 0.03815\n",
      "Mean Value Loss: 0.19827\n",
      "-------------------------\n",
      "Iterations 166 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.90341\n",
      "Final KL: 0.09616\n",
      "Mean Policy Loss: 0.04335\n",
      "Mean Value Loss: 0.66840\n",
      "-------------------------\n",
      "Iterations 167 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.92988\n",
      "Final KL: 0.15312\n",
      "Mean Policy Loss: 0.02628\n",
      "Mean Value Loss: 0.26259\n",
      "-------------------------\n",
      "Iterations 168 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.66627\n",
      "Final KL: 0.06962\n",
      "Mean Policy Loss: 0.00897\n",
      "Mean Value Loss: 0.44230\n",
      "-------------------------\n",
      "Iterations 169 Complete\n",
      "Epochs 3 \n",
      "Mean Rtg: -0.72070\n",
      "Final KL: 0.05901\n",
      "Mean Policy Loss: 0.00997\n",
      "Mean Value Loss: 0.29687\n",
      "-------------------------\n",
      "Iterations 170 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.69068\n",
      "Final KL: 0.05018\n",
      "Mean Policy Loss: 0.00481\n",
      "Mean Value Loss: 0.50075\n",
      "-------------------------\n",
      "Iterations 171 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.67046\n",
      "Final KL: 188.12045\n",
      "Mean Policy Loss: 0.00227\n",
      "Mean Value Loss: 0.20110\n",
      "-------------------------\n",
      "Iterations 172 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.59094\n",
      "Final KL: 0.18783\n",
      "Mean Policy Loss: 0.00981\n",
      "Mean Value Loss: 0.24608\n",
      "-------------------------\n",
      "Iterations 173 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.84263\n",
      "Final KL: 0.36908\n",
      "Mean Policy Loss: 0.74782\n",
      "Mean Value Loss: 0.40955\n",
      "-------------------------\n",
      "Iterations 174 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.62255\n",
      "Final KL: 0.11340\n",
      "Mean Policy Loss: 0.02000\n",
      "Mean Value Loss: 0.27345\n",
      "-------------------------\n",
      "Iterations 175 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.95138\n",
      "Final KL: 0.09261\n",
      "Mean Policy Loss: 0.00141\n",
      "Mean Value Loss: 0.80072\n",
      "-------------------------\n",
      "Iterations 176 Complete\n",
      "Epochs 3 \n",
      "Mean Rtg: -0.86119\n",
      "Final KL: 0.06127\n",
      "Mean Policy Loss: -0.00572\n",
      "Mean Value Loss: 0.37375\n",
      "-------------------------\n",
      "Iterations 177 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.97047\n",
      "Final KL: 8.16565\n",
      "Mean Policy Loss: 0.00875\n",
      "Mean Value Loss: 0.70958\n",
      "-------------------------\n",
      "Iterations 178 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.76625\n",
      "Final KL: 0.09378\n",
      "Mean Policy Loss: 0.01123\n",
      "Mean Value Loss: 0.40424\n",
      "-------------------------\n",
      "Iterations 179 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.65088\n",
      "Final KL: 0.81233\n",
      "Mean Policy Loss: 0.01641\n",
      "Mean Value Loss: 0.18285\n",
      "-------------------------\n",
      "Iterations 180 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.74721\n",
      "Final KL: 19.67869\n",
      "Mean Policy Loss: 0.00427\n",
      "Mean Value Loss: 0.16596\n",
      "-------------------------\n",
      "Iterations 181 Complete\n",
      "Epochs 6 \n",
      "Mean Rtg: -0.68983\n",
      "Final KL: 0.08735\n",
      "Mean Policy Loss: -0.00995\n",
      "Mean Value Loss: 0.14145\n",
      "-------------------------\n",
      "Iterations 182 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.72114\n",
      "Final KL: 0.06639\n",
      "Mean Policy Loss: 0.02580\n",
      "Mean Value Loss: 0.16423\n",
      "-------------------------\n",
      "Iterations 183 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.78571\n",
      "Final KL: 0.07677\n",
      "Mean Policy Loss: 0.06703\n",
      "Mean Value Loss: 0.34528\n",
      "-------------------------\n",
      "Iterations 184 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.90550\n",
      "Final KL: 143.12404\n",
      "Mean Policy Loss: 0.02018\n",
      "Mean Value Loss: 0.56768\n",
      "-------------------------\n",
      "Iterations 185 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.53173\n",
      "Final KL: 0.79955\n",
      "Mean Policy Loss: 0.06000\n",
      "Mean Value Loss: 0.16569\n",
      "-------------------------\n",
      "Iterations 186 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.61985\n",
      "Final KL: 35.02869\n",
      "Mean Policy Loss: 0.02767\n",
      "Mean Value Loss: 0.36289\n",
      "-------------------------\n",
      "Iterations 187 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.85850\n",
      "Final KL: 0.07626\n",
      "Mean Policy Loss: 0.00859\n",
      "Mean Value Loss: 0.37712\n",
      "-------------------------\n",
      "Iterations 188 Complete\n",
      "Epochs 5 \n",
      "Mean Rtg: -0.63892\n",
      "Final KL: 0.05003\n",
      "Mean Policy Loss: -0.00505\n",
      "Mean Value Loss: 0.11533\n",
      "-------------------------\n",
      "Iterations 189 Complete\n",
      "Epochs 8 \n",
      "Mean Rtg: -1.08451\n",
      "Final KL: 0.06949\n",
      "Mean Policy Loss: -0.00537\n",
      "Mean Value Loss: 0.31138\n",
      "-------------------------\n",
      "Iterations 190 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.47693\n",
      "Final KL: 0.21035\n",
      "Mean Policy Loss: 0.02148\n",
      "Mean Value Loss: 0.18373\n",
      "-------------------------\n",
      "Iterations 191 Complete\n",
      "Epochs 3 \n",
      "Mean Rtg: -0.78289\n",
      "Final KL: 0.05550\n",
      "Mean Policy Loss: 0.01001\n",
      "Mean Value Loss: 0.21035\n",
      "-------------------------\n",
      "Iterations 192 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.76687\n",
      "Final KL: 4.63206\n",
      "Mean Policy Loss: 0.00148\n",
      "Mean Value Loss: 0.47834\n",
      "-------------------------\n",
      "Iterations 193 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.73324\n",
      "Final KL: 4.03459\n",
      "Mean Policy Loss: 0.00407\n",
      "Mean Value Loss: 0.26582\n",
      "-------------------------\n",
      "Iterations 194 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.76524\n",
      "Final KL: 0.57232\n",
      "Mean Policy Loss: 0.03524\n",
      "Mean Value Loss: 0.46714\n",
      "-------------------------\n",
      "Iterations 195 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.83902\n",
      "Final KL: 0.07664\n",
      "Mean Policy Loss: 0.00449\n",
      "Mean Value Loss: 0.37500\n",
      "-------------------------\n",
      "Iterations 196 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.81968\n",
      "Final KL: 6.25914\n",
      "Mean Policy Loss: 0.00810\n",
      "Mean Value Loss: 0.27970\n",
      "-------------------------\n",
      "Iterations 197 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.59806\n",
      "Final KL: 0.10876\n",
      "Mean Policy Loss: 0.00618\n",
      "Mean Value Loss: 0.17782\n",
      "-------------------------\n",
      "Iterations 198 Complete\n",
      "Epochs 3 \n",
      "Mean Rtg: -0.66280\n",
      "Final KL: 0.13576\n",
      "Mean Policy Loss: 0.01641\n",
      "Mean Value Loss: 0.19638\n",
      "-------------------------\n",
      "Iterations 199 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.82867\n",
      "Final KL: 0.12445\n",
      "Mean Policy Loss: 0.00434\n",
      "Mean Value Loss: 0.27965\n",
      "-------------------------\n",
      "Iterations 200 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.74614\n",
      "Final KL: 0.06464\n",
      "Mean Policy Loss: 0.01148\n",
      "Mean Value Loss: 0.23914\n",
      "-------------------------\n",
      "Iterations 201 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.78461\n",
      "Final KL: 0.47957\n",
      "Mean Policy Loss: 0.05145\n",
      "Mean Value Loss: 0.27355\n",
      "-------------------------\n",
      "Iterations 202 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.51355\n",
      "Final KL: 0.28574\n",
      "Mean Policy Loss: 0.07637\n",
      "Mean Value Loss: 0.12418\n",
      "-------------------------\n",
      "Iterations 203 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.89400\n",
      "Final KL: 0.17915\n",
      "Mean Policy Loss: 0.00079\n",
      "Mean Value Loss: 0.47750\n",
      "-------------------------\n",
      "Iterations 204 Complete\n",
      "Epochs 10 \n",
      "Mean Rtg: -0.75899\n",
      "Final KL: 0.02665\n",
      "Mean Policy Loss: -0.00534\n",
      "Mean Value Loss: 0.15852\n",
      "-------------------------\n",
      "Iterations 205 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.54303\n",
      "Final KL: 0.08975\n",
      "Mean Policy Loss: 0.03263\n",
      "Mean Value Loss: 0.14832\n",
      "-------------------------\n",
      "Iterations 206 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.85889\n",
      "Final KL: 0.05217\n",
      "Mean Policy Loss: 0.01796\n",
      "Mean Value Loss: 0.41478\n",
      "-------------------------\n",
      "Iterations 207 Complete\n",
      "Epochs 3 \n",
      "Mean Rtg: -0.79023\n",
      "Final KL: 0.07333\n",
      "Mean Policy Loss: 0.00216\n",
      "Mean Value Loss: 0.22637\n",
      "-------------------------\n",
      "Iterations 208 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.54048\n",
      "Final KL: 0.10615\n",
      "Mean Policy Loss: 0.05015\n",
      "Mean Value Loss: 0.16583\n",
      "-------------------------\n",
      "Iterations 209 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.96780\n",
      "Final KL: 0.17903\n",
      "Mean Policy Loss: 0.01765\n",
      "Mean Value Loss: 0.51336\n",
      "-------------------------\n",
      "Iterations 210 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.68358\n",
      "Final KL: 0.06321\n",
      "Mean Policy Loss: 0.02343\n",
      "Mean Value Loss: 0.22003\n",
      "-------------------------\n",
      "Iterations 211 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.83514\n",
      "Final KL: 0.42895\n",
      "Mean Policy Loss: 0.03047\n",
      "Mean Value Loss: 0.41689\n",
      "-------------------------\n",
      "Iterations 212 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.79612\n",
      "Final KL: 0.06028\n",
      "Mean Policy Loss: 0.00771\n",
      "Mean Value Loss: 0.36723\n",
      "-------------------------\n",
      "Iterations 213 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.59567\n",
      "Final KL: 0.49154\n",
      "Mean Policy Loss: 0.01461\n",
      "Mean Value Loss: 0.11743\n",
      "-------------------------\n",
      "Iterations 214 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.94154\n",
      "Final KL: 0.14183\n",
      "Mean Policy Loss: 0.03194\n",
      "Mean Value Loss: 1.03165\n",
      "-------------------------\n",
      "Iterations 215 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.92998\n",
      "Final KL: 0.21834\n",
      "Mean Policy Loss: 0.02351\n",
      "Mean Value Loss: 0.34718\n",
      "-------------------------\n",
      "Iterations 216 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -1.03416\n",
      "Final KL: 0.08608\n",
      "Mean Policy Loss: 0.02833\n",
      "Mean Value Loss: 1.01894\n",
      "-------------------------\n",
      "Iterations 217 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.72713\n",
      "Final KL: 0.25614\n",
      "Mean Policy Loss: -0.00230\n",
      "Mean Value Loss: 0.19317\n",
      "-------------------------\n",
      "Iterations 218 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.66214\n",
      "Final KL: 0.09605\n",
      "Mean Policy Loss: 0.01393\n",
      "Mean Value Loss: 0.16856\n",
      "-------------------------\n",
      "Iterations 219 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.71953\n",
      "Final KL: 0.07473\n",
      "Mean Policy Loss: 0.01214\n",
      "Mean Value Loss: 0.12823\n",
      "-------------------------\n",
      "Iterations 220 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.61943\n",
      "Final KL: 0.18322\n",
      "Mean Policy Loss: 0.00670\n",
      "Mean Value Loss: 0.22357\n",
      "-------------------------\n",
      "Iterations 221 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.62958\n",
      "Final KL: 0.15920\n",
      "Mean Policy Loss: 0.00292\n",
      "Mean Value Loss: 0.27855\n",
      "-------------------------\n",
      "Iterations 222 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -1.04359\n",
      "Final KL: 0.06873\n",
      "Mean Policy Loss: 0.01194\n",
      "Mean Value Loss: 1.14939\n",
      "-------------------------\n",
      "Iterations 223 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.85748\n",
      "Final KL: 0.51827\n",
      "Mean Policy Loss: 0.01086\n",
      "Mean Value Loss: 0.29234\n",
      "-------------------------\n",
      "Iterations 224 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.78013\n",
      "Final KL: 0.40233\n",
      "Mean Policy Loss: 0.01161\n",
      "Mean Value Loss: 0.26765\n",
      "-------------------------\n",
      "Iterations 225 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.69564\n",
      "Final KL: 1.44967\n",
      "Mean Policy Loss: 0.01909\n",
      "Mean Value Loss: 0.14885\n",
      "-------------------------\n",
      "Iterations 226 Complete\n",
      "Epochs 3 \n",
      "Mean Rtg: -0.65000\n",
      "Final KL: 0.08207\n",
      "Mean Policy Loss: 0.00317\n",
      "Mean Value Loss: 0.13457\n",
      "-------------------------\n",
      "Iterations 227 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.68993\n",
      "Final KL: 0.58314\n",
      "Mean Policy Loss: 0.02467\n",
      "Mean Value Loss: 0.23591\n",
      "-------------------------\n",
      "Iterations 228 Complete\n",
      "Epochs 10 \n",
      "Mean Rtg: -0.71072\n",
      "Final KL: 0.02579\n",
      "Mean Policy Loss: -0.01393\n",
      "Mean Value Loss: 0.21182\n",
      "-------------------------\n",
      "Iterations 229 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.94118\n",
      "Final KL: 0.18671\n",
      "Mean Policy Loss: 0.00014\n",
      "Mean Value Loss: 0.47350\n",
      "-------------------------\n",
      "Iterations 230 Complete\n",
      "Epochs 10 \n",
      "Mean Rtg: -0.58601\n",
      "Final KL: 0.03406\n",
      "Mean Policy Loss: -0.01168\n",
      "Mean Value Loss: 0.38294\n",
      "-------------------------\n",
      "Iterations 231 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.66317\n",
      "Final KL: 534.46454\n",
      "Mean Policy Loss: 0.00480\n",
      "Mean Value Loss: 0.51501\n",
      "-------------------------\n",
      "Iterations 232 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.51702\n",
      "Final KL: 0.13360\n",
      "Mean Policy Loss: 0.01750\n",
      "Mean Value Loss: 0.15060\n",
      "-------------------------\n",
      "Iterations 233 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.55708\n",
      "Final KL: 2.71340\n",
      "Mean Policy Loss: 0.05581\n",
      "Mean Value Loss: 0.11493\n",
      "-------------------------\n",
      "Iterations 234 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.75738\n",
      "Final KL: 0.05125\n",
      "Mean Policy Loss: 0.00648\n",
      "Mean Value Loss: 0.34273\n",
      "-------------------------\n",
      "Iterations 235 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.70148\n",
      "Final KL: 18270722048.00000\n",
      "Mean Policy Loss: 0.06457\n",
      "Mean Value Loss: 0.29415\n",
      "-------------------------\n",
      "Iterations 236 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.85981\n",
      "Final KL: 0.16301\n",
      "Mean Policy Loss: 0.01408\n",
      "Mean Value Loss: 0.71164\n",
      "-------------------------\n",
      "Iterations 237 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.93600\n",
      "Final KL: 0.05012\n",
      "Mean Policy Loss: 0.00163\n",
      "Mean Value Loss: 0.31599\n",
      "-------------------------\n",
      "Iterations 238 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.77399\n",
      "Final KL: 0.09680\n",
      "Mean Policy Loss: 0.17004\n",
      "Mean Value Loss: 0.34856\n",
      "-------------------------\n",
      "Iterations 239 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.88008\n",
      "Final KL: 0.37465\n",
      "Mean Policy Loss: 0.07938\n",
      "Mean Value Loss: 0.36565\n",
      "-------------------------\n",
      "Iterations 240 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.63034\n",
      "Final KL: 0.05357\n",
      "Mean Policy Loss: 0.01018\n",
      "Mean Value Loss: 0.30297\n",
      "-------------------------\n",
      "Iterations 241 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -1.01952\n",
      "Final KL: 58920488.00000\n",
      "Mean Policy Loss: 0.01131\n",
      "Mean Value Loss: 0.44789\n",
      "-------------------------\n",
      "Iterations 242 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.69014\n",
      "Final KL: 0.30338\n",
      "Mean Policy Loss: -0.00380\n",
      "Mean Value Loss: 0.24476\n",
      "-------------------------\n",
      "Iterations 243 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.62321\n",
      "Final KL: 0.20473\n",
      "Mean Policy Loss: 0.01454\n",
      "Mean Value Loss: 0.29340\n",
      "-------------------------\n",
      "Iterations 244 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.61128\n",
      "Final KL: 2741644.75000\n",
      "Mean Policy Loss: 0.00997\n",
      "Mean Value Loss: 0.20411\n",
      "-------------------------\n",
      "Iterations 245 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.73571\n",
      "Final KL: 0.42953\n",
      "Mean Policy Loss: 0.02616\n",
      "Mean Value Loss: 0.23642\n",
      "-------------------------\n",
      "Iterations 246 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.92250\n",
      "Final KL: 0.46645\n",
      "Mean Policy Loss: 0.02064\n",
      "Mean Value Loss: 0.32398\n",
      "-------------------------\n",
      "Iterations 247 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.70405\n",
      "Final KL: 1.87389\n",
      "Mean Policy Loss: 0.00231\n",
      "Mean Value Loss: 0.18573\n",
      "-------------------------\n",
      "Iterations 248 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.75519\n",
      "Final KL: 1.12442\n",
      "Mean Policy Loss: 0.17522\n",
      "Mean Value Loss: 0.12226\n",
      "-------------------------\n",
      "Iterations 249 Complete\n",
      "Epochs 1 \n",
      "Mean Rtg: -0.78376\n",
      "Final KL: 0.11917\n",
      "Mean Policy Loss: 0.02818\n",
      "Mean Value Loss: 0.13069\n",
      "-------------------------\n",
      "Iterations 250 Complete\n",
      "Epochs 2 \n",
      "Mean Rtg: -0.58755\n",
      "Final KL: 0.14154\n",
      "Mean Policy Loss: 0.01920\n",
      "Mean Value Loss: 0.07325\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ACGatePolicy(Chain(Dense(14 => 64, relu), Dense(64 => 64, relu), Dense(64 => 2, softsign)), Chain(Dense(14 => 64, relu), Dense(64 => 64, relu), Dense(64 => 1, softsign)), Chain(Dense(14 => 64, relu), Dense(64 => 64, relu), Dense(64 => 1)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACpolicy = PPO(Pretraining_Env;iterations=250,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f87688e8-f92e-4ed4-9b3d-c9fb51114381",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch: layer Dense(14 => 64, relu) expects size(input, 1) == 14, but got 1-element Vector{Float64}",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch: layer Dense(14 => 64, relu) expects size(input, 1) == 14, but got 1-element Vector{Float64}",
      "",
      "Stacktrace:",
      " [1] _size_check(layer::Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, x::Vector{Float64}, ::Pair{Int64, Int64})",
      "   @ Flux C:\\Users\\Bikrant\\.julia\\packages\\Flux\\CUn7U\\src\\layers\\basic.jl:196",
      " [2] (::Dense{typeof(relu), Matrix{Float32}, Vector{Float32}})(x::Vector{Float64})",
      "   @ Flux C:\\Users\\Bikrant\\.julia\\packages\\Flux\\CUn7U\\src\\layers\\basic.jl:172",
      " [3] macro expansion",
      "   @ C:\\Users\\Bikrant\\.julia\\packages\\Flux\\CUn7U\\src\\layers\\basic.jl:53 [inlined]",
      " [4] _applychain",
      "   @ C:\\Users\\Bikrant\\.julia\\packages\\Flux\\CUn7U\\src\\layers\\basic.jl:53 [inlined]",
      " [5] (::Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(softsign), Matrix{Float32}, Vector{Float32}}}})(x::Vector{Float64})",
      "   @ Flux C:\\Users\\Bikrant\\.julia\\packages\\Flux\\CUn7U\\src\\layers\\basic.jl:51",
      " [6] (::var\"#184#185\")(v::Float64)",
      "   @ Main .\\none:0",
      " [7] iterate",
      "   @ .\\generator.jl:47 [inlined]",
      " [8] collect(itr::Base.Generator{StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}, var\"#184#185\"})",
      "   @ Base .\\array.jl:834",
      " [9] top-level scope",
      "   @ In[13]:2"
     ]
    }
   ],
   "source": [
    "x = range(0,2*pi,1000)\n",
    "y = [ACpolicy.std_network([v])[1] for v in x]\n",
    "using CairoMakie\n",
    "lines(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d54116d9-d477-4f7b-a8cd-f14438f90db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 2.5132741228718345"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RLBase.reset!(Pretraining_Env,angle = [range(0,2*pi,11)[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d1e114e-8b4c-4b9d-8e4e-0bb612279cf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: objects of type ACGatePolicy are not callable",
     "output_type": "error",
     "traceback": [
      "MethodError: objects of type ACGatePolicy are not callable",
      "",
      "Stacktrace:",
      " [1] SampleTrajectory(Policy::ACGatePolicy, env::PretrainingGateEnv; deterministic::Bool, kwargs::@Kwargs{})",
      "   @ Main C:\\Users\\Bikrant\\PicoRL\\RL-Copy1.jl:225",
      " [2] top-level scope",
      "   @ In[15]:1"
     ]
    }
   ],
   "source": [
    "rewards,acts,states =SampleTrajectory(ACpolicy,Pretraining_Env;deterministic=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d055d59-4f43-4780-a2aa-a5f359f703d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×51 Matrix{Float64}:\n",
       " 0.0  1.83246e-20  -0.0196885    -0.0507178   …  0.0708192  0.0285495   0.0\n",
       " 0.0  6.10707e-20   0.000972287   0.00170063     0.0179483  0.00665824  0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RZ_traj[:a5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87fd2310-a116-4031-a0aa-06ce20fe0002",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `Figure` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Figure` not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[17]:1"
     ]
    }
   ],
   "source": [
    "fig = Figure()\n",
    "ax = Axis(fig[1,1])\n",
    "lines!(ax,1:n_steps,Pretraining_Env.a[1,:])\n",
    "lines!(ax,1:n_steps,RZ_traj[:a5][1,:])\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
